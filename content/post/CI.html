---
title: "What is a Confidence Interval?"
author: "Megha Joshi"
date: 2021-05-11
categories: ["R"]
tags: ["statistics", "confidence intervals"]
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<pre class="r"><code>library(tidyverse)
library(knitr)</code></pre>
<div id="distributions" class="section level1">
<h1>Distributions</h1>
<p>There are three kinds of distributions:</p>
<div id="population-distribution" class="section level2">
<h2>Population Distribution</h2>
<p>There are around 15 million adults in Texas and I am interested in estimating the average height of all adult Texans. I cannot go out and measure everyone’s height due to financial, capacity constraints etc.</p>
<p>For the sake of this example, I am going to draw up a hypothetical population distribution of heights of all people in Texas. Below is a histogram showing the distribution of the heights across all adults in the population:</p>
<pre class="r"><code>options(scipen = 10000)
set.seed(04302021)

# i am setting min 4 and max 7
heights &lt;- tibble(heights = pmax(4, pmin(7, rnorm(n = 15000000, mean = 5.5, sd = .5))))

ggplot(heights, aes(x = heights)) +
  geom_histogram(alpha = 0.5, 
                 bins = 50, 
                 fill = &quot;blue4&quot;) +
  scale_y_continuous(labels = scales::comma) +
  labs(x = &quot;Heights of All Texas Adults&quot;, 
       y = &quot;Number of People in Texas&quot;,
       title = &quot;Population Distribution of Heights in Texas&quot;) +
  theme_minimal()</code></pre>
<p><img src="/post/CI_files/figure-html/unnamed-chunk-2-1.png" width="576" /></p>
<p>The <em>population distribution</em> is the distribution of heights of all adults in Texas.</p>
<p>The mean of the distribution is 5.5 and the standard deviation of the distribution is 0.499. These are the population <em>parameters</em>:</p>
<pre class="r"><code>mean(heights$heights)

sd(heights$heights)</code></pre>
<p>The heights range from 4 to 7 ~ this is the range of true heights in the population, which we won’t typically know because we don’t go out and measure heights of 15 million people.</p>
</div>
<div id="sample-distribution" class="section level2">
<h2>Sample Distribution</h2>
<p>I can’t go out and measure everyone in the population so I take a sample of 10. Here is the distribution of heights in that sample:</p>
<pre class="r"><code>set.seed(05012021)
sample_1 &lt;- tibble(heights = sample(heights$heights, size = 10))

ggplot(sample_1, aes(x = heights)) +
  geom_histogram(alpha = 0.5, 
                 bins = 10, 
                 fill = &quot;darkolivegreen&quot;) +
  scale_y_continuous(breaks = seq(1, 3, 1)) +
  labs(x = &quot;Heights of People in My Sample&quot;, 
       y = &quot;Number of People in the Sample&quot;,
       title = &quot;Distribution of Heights in My Sample&quot;) +
  theme_minimal()</code></pre>
<p><img src="/post/CI_files/figure-html/unnamed-chunk-4-1.png" width="576" /></p>
<p>The <em>sample distribution</em> is the distribution of heights in my sample.</p>
<p>The mean of the sample of heights is 5.482 and the standard deviation is 0.593. This is the sample mean and the sample sd, the sample <em>statistics</em>. The sample mean is not going to be exactly the same as the population parameter and will differ from sample to sample.</p>
<pre class="r"><code>mean(sample_1$heights)
sd(sample_1$heights) </code></pre>
<div id="confidence-intervals" class="section level3">
<h3>Confidence Intervals</h3>
<div id="first-sample" class="section level4">
<h4>First sample</h4>
<p>Below is the the 95% confidence interval of the sample mean of the sample I drew above of 10 people:</p>
<pre class="r"><code>calculate_ci &lt;- function(m, sd, n = 10){
  
  se &lt;- sd / sqrt(n)
  ci &lt;-  m + c(-1, 1) * 1.96 * se
  
  tibble(mean = m,
         ci_l = ci[1],
         ci_u = ci[2])
  
}

m_s1 &lt;- mean(sample_1$heights)
sd_s1 &lt;- sd(sample_1$heights) 

calculate_ci(m = m_s1, sd = sd_s1) %&gt;%
  kable(digits = 3) </code></pre>
<table>
<thead>
<tr class="header">
<th align="right">mean</th>
<th align="right">ci_l</th>
<th align="right">ci_u</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">5.482</td>
<td align="right">5.114</td>
<td align="right">5.85</td>
</tr>
</tbody>
</table>
<p>In this example, the true population mean is in the CI. Note that the CI does not capture the range of the heights in the population (which is 4 to 7).</p>
</div>
<div id="another-sample" class="section level4">
<h4>Another sample</h4>
<p>I take another sample and estimate the mean and CI:</p>
<pre class="r"><code>set.seed(05022021)
sample_2 &lt;- tibble(heights = sample(heights$heights, size = 10))

m_s2 &lt;- mean(sample_2$heights)
sd_s2 &lt;- sd(sample_2$heights) 

calculate_ci(m = m_s2, sd = sd_s2) %&gt;%
  kable(digits = 3) </code></pre>
<table>
<thead>
<tr class="header">
<th align="right">mean</th>
<th align="right">ci_l</th>
<th align="right">ci_u</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">5.592</td>
<td align="right">5.192</td>
<td align="right">5.992</td>
</tr>
</tbody>
</table>
<p>This CI contains 5.5. Notice that the mean is close to 5.6 which is a bit different from the population parameter 5.5, and different from the sample mean of the first sample.</p>
</div>
<div id="extreme-sample" class="section level4">
<h4>Extreme sample</h4>
<p>I take another sample and this time I am not so lucky and draw 10 quite tall people by chance. I calculate the mean and the CI:</p>
<pre class="r"><code>tall_folx &lt;- 
  heights %&gt;%
  filter(heights &gt; 6)

set.seed(05032021)

sample_3 &lt;- tibble(heights = sample(tall_folx$heights, size = 10))

m_s3 &lt;- mean(sample_3$heights)
sd_s3 &lt;- sd(sample_3$heights) 

calculate_ci(m = m_s3, sd = sd_s3) %&gt;%
  kable(digits = 3) </code></pre>
<table>
<thead>
<tr class="header">
<th align="right">mean</th>
<th align="right">ci_l</th>
<th align="right">ci_u</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">6.216</td>
<td align="right">6.086</td>
<td align="right">6.345</td>
</tr>
</tbody>
</table>
<p>This CI definitely doesn’t capture the 5.5 average population height. It doesn’t say anything about the true population height which we know is 5.5.</p>
<p>The sample mean here is different from the sample mean of the first two samples and different from the population parameter 5.5.</p>
<p>In applied analysis, we won’t know what the true mean is so we won’t know if the CI contains the true mean.</p>
</div>
</div>
<div id="thought-exercise" class="section level3">
<h3>Thought exercise</h3>
<p>Now as would happen in applied analysis, pretend that we don’t know 5.5 is the true mean. How would we know if CI’s from sample 1, sample 2, and sample 3 contain the true parameter? We wouldn’t know.</p>
</div>
</div>
<div id="sampling-distribution" class="section level2">
<h2>Sampling Distribution</h2>
<p>Now I have data from a sample and want to use that data to infer something about a population. The sample is typically much smaller in size than the population, 10 people vs 15 million people in this example, so how do I measure how certain we are about the estimate derived from the sample?</p>
<p>To measure the uncertainty in my estimated height, I would rely on something called the sampling distribution. Below is a histogram showing the the distribution of 10,000 sample means from 10,000 samples drawn randomly from the population each with sample size of 10.</p>
<pre class="r"><code>set.seed(05042021)

samples_ci &lt;- 
  rerun(10000, {
    x &lt;- sample(heights$heights, size = 10)
    m &lt;- mean(x)
    sd &lt;- sd(x)
    n &lt;- 10
    tibble(mean = m,
           ci_l = m - 1.96 * sd/ sqrt(n),
           ci_u = m + 1.96 * sd/ sqrt(n))
  }) %&gt;%
  bind_rows()

samples_ci %&gt;%
  ggplot(aes(x = mean)) +
  geom_histogram(alpha = 0.5, 
                 bins = 50, 
                 fill = &quot;dark red&quot;) +
  labs(x = &quot;Average Heights from Different Samples&quot;, 
       y = &quot;Number of Samples&quot;,
       title = &quot;Distribution of Average Sample Heights&quot;) +
  theme_minimal()</code></pre>
<p><img src="/post/CI_files/figure-html/unnamed-chunk-9-1.png" width="576" /></p>
<p>This distribution is different from the population distribution. It is not the distribution of heights of all people. It is the distribution of means estimated from different samples - a lot of different samples. And note that I am not drawing all possible samples. I am only drawing 10,000 samples.</p>
<p>The <em>sampling distribution</em> is the distribution of a statistic (e.g., sample mean) across all possible samples.</p>
<p>In applied analysis, we don’t know what the sampling distribution is as we won’t be able to take repeated samples infinite number of times. Statistical models and assumptions help us get at the sampling distribution which then lets us measure uncertainty in our estimates.</p>
<div id="standard-error---measure-of-uncertainty" class="section level3">
<h3>Standard error - measure of uncertainty</h3>
<p>The standard deviation of the sampling distribution is the <em>standard error</em>. The standard error indicates how precise or certain a statistic is. In applied analysis, we typically estimate the standard error using statistical models and assumptions.</p>
<div id="what-is-precision" class="section level4">
<h4>What is precision?</h4>
<p>Precision, in statistics, captures the variability of sample means - deviation of sample means from the mean of sample means. Precision is the opposite of standard error ~ small standard error = high precision. Note that we don’t know the true standard error we estimate it too :D</p>
</div>
</div>
<div id="cis-of-sample-means-in-sampling-distribution" class="section level3">
<h3>CI’s of Sample Means in Sampling Distribution</h3>
<p>In the graph of the sampling distribution above above, some of the sample means are way out there. For example there are some near 6. The table below shows 5 of these sample means and their corresponding CIs. The CIs don’t contain 5.5, the true mean.</p>
<pre class="r"><code>samples_ci %&gt;%
  filter(mean &gt; 5.9) %&gt;%
  tail(n = 5) %&gt;%
  kable(digits = 3) </code></pre>
<table>
<thead>
<tr class="header">
<th align="right">mean</th>
<th align="right">ci_l</th>
<th align="right">ci_u</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">5.911</td>
<td align="right">5.566</td>
<td align="right">6.257</td>
</tr>
<tr class="even">
<td align="right">5.948</td>
<td align="right">5.565</td>
<td align="right">6.331</td>
</tr>
<tr class="odd">
<td align="right">5.929</td>
<td align="right">5.625</td>
<td align="right">6.234</td>
</tr>
<tr class="even">
<td align="right">5.929</td>
<td align="right">5.622</td>
<td align="right">6.236</td>
</tr>
<tr class="odd">
<td align="right">5.922</td>
<td align="right">5.529</td>
<td align="right">6.315</td>
</tr>
</tbody>
</table>
<p>Below are the sample means and CI’s at the lower end of the distribution. These CI’s also don’t contain 5.5.</p>
<pre class="r"><code>samples_ci %&gt;%
  filter(mean &lt; 5) %&gt;%
  tail(n = 5) %&gt;%
  kable(digits = 3) </code></pre>
<table>
<thead>
<tr class="header">
<th align="right">mean</th>
<th align="right">ci_l</th>
<th align="right">ci_u</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">4.988</td>
<td align="right">4.711</td>
<td align="right">5.265</td>
</tr>
<tr class="even">
<td align="right">4.914</td>
<td align="right">4.733</td>
<td align="right">5.095</td>
</tr>
<tr class="odd">
<td align="right">4.979</td>
<td align="right">4.621</td>
<td align="right">5.336</td>
</tr>
<tr class="even">
<td align="right">4.981</td>
<td align="right">4.702</td>
<td align="right">5.261</td>
</tr>
<tr class="odd">
<td align="right">4.976</td>
<td align="right">4.729</td>
<td align="right">5.224</td>
</tr>
</tbody>
</table>
<p>Note here that the means at the extreme ends of the sampling distribution are from simple random samples of the population. So in real applied analysis, we could get one of those samples with extreme heights by chance and our CI won’t capture the true mean.</p>
<div id="thought-exercise-1" class="section level4">
<h4>Thought exercise</h4>
<p>Now as would happen in applied analysis, pretend that we don’t know 5.5 is the true mean. How would we know any of these 10,000 CI’s contain the population parameter? We wouldn’t.</p>
</div>
</div>
</div>
</div>
<div id="what-is-ci-then" class="section level1">
<h1>What is CI then?</h1>
<p>I calculated CIs above when I drew samples from the population. But what is a CI?</p>
<p>In repeated sampling as above, if I were to create confidence intervals around each of the means, approximately 95% of them would capture the true population mean 5.5.</p>
<p>The proportion of CI’s from the 10,000 samples that I drew above that contain the true parameter is:</p>
<pre class="r"><code>samples_ci &lt;- 
  samples_ci %&gt;%
  mutate(captures = ifelse(5.5 &lt; ci_u &amp; 5.5 &gt; ci_l, TRUE, FALSE)) 

samples_ci %&gt;%
  summarize(prop = mean(captures),
            n = sum(captures)) %&gt;%
  kable(digits = 3) </code></pre>
<table>
<thead>
<tr class="header">
<th align="right">prop</th>
<th align="right">n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0.914</td>
<td align="right">9144</td>
</tr>
</tbody>
</table>
<p>The proportion is close to 95%. Also note that I would need to take infinite number of samples to get close to 95%.</p>
<p>Note that the CI takes the following form:</p>
<p><span class="math display">\[CI = estimate \pm critical \times se\]</span></p>
<p>CI’s are built around an estimate plus and minus a critical value (like 1.96 for z normal distribution) times the standard error. The width of the CI is dependent on the standard error - which indicates how precise an estimate is.</p>
<p>CI’s are not built around the mean of the sample means (i.e., the center of the sampling distribution). If we knew what the sampling distribution was and what the center was and built CI around that center then we would capture where 95% of all the sample means fall. But, we don’t know what the sampling distribution is and only have one sample that could be in the center of the sampling distribution but by random chance could also be on the ends of the sampling distribution or could be a bit to the left or right of the center. We won’t know. The CI is built around that one sample statistic therefore, the CI does not give us the range of possible means.</p>
<div id="what-does-ci-tell-me" class="section level2">
<h2>What does CI tell me?</h2>
<p>The width of the confidence intervals tells me how precise the estimate is. When sample size is small, we won’t get very precise estimates. Estimated average heights will be too noisy, too different from sample to sample. When sample size is large, estimated average heights will be more precise. The table below shows mean and CIs calculated from a random sample of 5 people and from another random sample of 1000 people from the population distribution of heights.</p>
<pre class="r"><code>set.seed(05052021)
small_s4 &lt;- sample(heights$heights, size = 5)
m_s4 &lt;- mean(small_s4)
sd_s4 &lt;- sd(small_s4)
n_s4 &lt;- length(small_s4)

set.seed(05062021)
large_s5 &lt;- sample(heights$heights, size = 1000)
m_s5 &lt;- mean(large_s5)
sd_s5 &lt;- sd(large_s5)
n_s5 &lt;- length(large_s5)

small &lt;- calculate_ci(m = m_s4, sd = sd_s4, n = n_s4) %&gt;%
  mutate(n = n_s4)

large &lt;- calculate_ci(m = m_s5, sd = sd_s5, n = n_s5) %&gt;%
  mutate(n = n_s5)

bind_rows(small, large) %&gt;%
  mutate(width = ci_u - ci_l) %&gt;%
  select(n, everything()) %&gt;%
  kable(digits = 3)</code></pre>
<table>
<thead>
<tr class="header">
<th align="right">n</th>
<th align="right">mean</th>
<th align="right">ci_l</th>
<th align="right">ci_u</th>
<th align="right">width</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">5</td>
<td align="right">5.592</td>
<td align="right">5.266</td>
<td align="right">5.919</td>
<td align="right">0.654</td>
</tr>
<tr class="even">
<td align="right">1000</td>
<td align="right">5.490</td>
<td align="right">5.459</td>
<td align="right">5.521</td>
<td align="right">0.062</td>
</tr>
</tbody>
</table>
<p>In the example above, for the sample with <span class="math inline">\(n = 5\)</span>, the CI is wide compared to the CI from the sample with <span class="math inline">\(n = 1000\)</span>. When we take a small sample, sample means from repeated samples will tend to vary more - we are less certain about the estimate - the estimate is less precise - the CI is wide.</p>
<p>For the sample with <span class="math inline">\(n = 1000\)</span>, you can see that the CI is not as wide as in the case where <span class="math inline">\(n = 5\)</span>. When we take a large sample, sample means from repeated samples will tend to vary less - we are more certain about the estimate - the estimate is more precise - the CI is narrow.</p>
<p>No matter how narrow or wide the CI is, with repeated sampling, only 95% of the CIs calculated will capture the true mean.</p>
<div id="what-does-it-all-mean" class="section level4">
<h4>What does it all mean?</h4>
<p>Precision just tells us that if we were to take repeated samples will the sample means be close to each other or really all over the place.</p>
</div>
</div>
<div id="what-does-the-ci-not-tell-me" class="section level2">
<h2>What does the CI not tell me?</h2>
<p>The CI is built around an estimate. It doesn’t say anything about the range of heights of all adult population of Texas, for example.</p>
<p>Also in applied analysis, we don’t know the true population mean. We only know that if we were to take infinite repeated samples of the same size under the same-ish condition and construct CI’s around the estimated means, 95% of the intervals will capture the true population mean. How do I know if the interval I created is one of the 95% that do capture the true mean or the one of the 5% that don’t capture the true mean. I don’t. Therefore, from the CI itself I don’t know the location of the true mean.</p>
<p>CI also does not say anything about my psychological level of confidence.</p>
</div>
<div id="how-do-i-know-then-if-my-estimate-is-close-to-the-true-mean" class="section level2">
<h2>How do I know then if my estimate is close to the true mean?</h2>
<p>Well you don’t, you just assume you do :) (A version of this joke was told to me by <a href="https://www.urban.org/author/robert-santos/publications">Rob Santos</a>).</p>
<p>We methodologists study methods under known data generating conditions and we study them under conditions where certain assumptions or conditions hold and when they don’t. We generate tens of thousands of samples ~ approximately creating the sampling distribution. From simulations, we measure accuracy, bias, precision etc. and we can measure those because we generate data based on true parameters that are known to us.</p>
<p>Then we recommend what method should be used under what conditions. This is why it is important to evaluate whether assumptions hold or not when you are running analyses :) Those assumptions can tell you how close the estimate is to the true mean.</p>
<div id="wait-what-is-precision-accuracy-bias" class="section level3">
<h3>Wait what is precision, accuracy, bias?</h3>
<p><img src="/img/precision_accuracy.png" /></p>
<p>Consider the <a href="https://manoa.hawaii.edu/exploringourfluidearth/physical/world-ocean/map-distortion/practices-science-precision-vs-accuracy">image above</a>. The center of the dart board is the population parameter, the population average height of 5.5. Each of the dart is a sample and where it lands is the sample statistic. The goal is for each statistic to be as close as possible to the center.</p>
<p><strong>Precision</strong> - Precision indicates that statistics from different samples are close to each other even if all the statistics are far away from the center. Panels B and D in the image above show high precision but note that in B the dart locations are far away from center.</p>
<p><strong>Bias</strong> - Bias indicates that the average of the locations of the darts is not close to the center - the true parameter. The darts can be far apart from each other but if you take an average of their locations that should be close to the center for an estimator to be unbiased. Panels C and D indicate low bias but note that in C darts are all over the place - any one sample is super far from the center - but if you take their average that average will be close to the center.</p>
<p><strong>Accuracy</strong> - Accuracy accounts for both bias and precision. The darts on average are close to the center and different darts are located close to each other. Panel D indicates high accuracy - this is the the ideal scenario where different samples don’t vary so much from each other and don’t vary on average from the true parameter. All the different darts land right near the center.</p>
<p>Panel A in the image above indicates low precision, high bias, and low accuracy.</p>
<div id="where-do-cis-fit-in-here" class="section level4">
<h4>Where do CI’s fit in here?</h4>
<p>CI’s give information on precision. We can get a narrow CI under scenario B and under scenario D. CI’s do not give information on accuracy. If the estimated mean is really far off from the true mean as is the case with the sample mean from the really tall people (sample 3), the CI is not going to capture the true mean. The CI is going to shift with that estimate.</p>
</div>
</div>
</div>
</div>
<div id="further-links" class="section level1">
<h1>Further links</h1>
<p><a href="https://rpsychologist.com/d3/ci/">CI explainer app with simulation</a></p>
<p><a href="https://towardsdatascience.com/why-overlapping-confidence-intervals-mean-nothing-about-statistical-significance-48360559900a">Why CI overlap does not say anything about statistical significance</a></p>
</div>
